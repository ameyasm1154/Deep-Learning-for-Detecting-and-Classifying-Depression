{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConditionGroupFileNames = os.listdir('data/condition')\n",
    "ControlGroupFileNames = os.listdir('data/control')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileName in ConditionGroupFileNames:\n",
    "    df = pd.read_csv('data/condition/'+str(fileName))\n",
    "    dates = df['date'].unique()\n",
    "    activityLevelsPerDay = []\n",
    "    for date in dates:\n",
    "        if len(df[df['date']==date]) == 1440:\n",
    "            temp = pd.DataFrame(df[df['date']==date]).drop(columns=['timestamp','date'])\n",
    "            activityLevelsPerDay.append(temp)\n",
    "    for dailyActivityLevel in activityLevelsPerDay:\n",
    "        activityVector = np.array(dailyActivityLevel[\"activity\"])\n",
    "        if len(activityVector) == 1440:\n",
    "            X.append(activityVector)\n",
    "            y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileName in ControlGroupFileNames:\n",
    "    df = pd.read_csv('data/control/'+str(fileName))\n",
    "    dates = df['date'].unique()\n",
    "    activityLevelsPerDay = []\n",
    "    for date in dates:\n",
    "        if len(df[df['date']==date]) == 1440:\n",
    "            temp = pd.DataFrame(df[df['date']==date]).drop(columns=['timestamp','date'])\n",
    "            activityLevelsPerDay.append(temp)\n",
    "    for dailyActivityLevel in activityLevelsPerDay:\n",
    "        activityVector = np.array(dailyActivityLevel[\"activity\"])\n",
    "        if len(activityVector) == 1440:\n",
    "            X.append(activityVector)\n",
    "            y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDict = list(zip(X, y))\n",
    "random.shuffle(combinedDict)\n",
    "X[:], y[:] = zip(*combinedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(X, (X.shape[0], 1, X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "accuracy_scores = []\n",
    "prec_scores = []\n",
    "rec_scores = []\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 65.05%\n",
      "recall_m: 0.16%\n",
      "precision_m: 0.42%\n",
      "f1_m: 0.23%\n",
      "\n",
      "\n",
      "accuracy: 65.05%\n",
      "recall_m: 0.00%\n",
      "precision_m: 0.00%\n",
      "f1_m: 0.00%\n",
      "\n",
      "\n",
      "accuracy: 65.05%\n",
      "recall_m: 0.00%\n",
      "precision_m: 0.00%\n",
      "f1_m: 0.00%\n",
      "\n",
      "\n",
      "accuracy: 65.05%\n",
      "recall_m: 0.36%\n",
      "precision_m: 0.54%\n",
      "f1_m: 0.40%\n",
      "\n",
      "\n",
      "accuracy: 65.05%\n",
      "recall_m: 0.00%\n",
      "precision_m: 0.00%\n",
      "f1_m: 0.00%\n",
      "\n",
      "\n",
      "accuracy: 65.05%\n",
      "recall_m: 0.00%\n",
      "precision_m: 0.00%\n",
      "f1_m: 0.00%\n",
      "\n",
      "\n",
      "accuracy: 63.11%\n",
      "recall_m: 0.13%\n",
      "precision_m: 0.35%\n",
      "f1_m: 0.19%\n",
      "\n",
      "\n",
      "accuracy: 64.08%\n",
      "recall_m: 0.12%\n",
      "precision_m: 0.29%\n",
      "f1_m: 0.16%\n",
      "\n",
      "\n",
      "accuracy: 65.05%\n",
      "recall_m: 0.00%\n",
      "precision_m: 0.00%\n",
      "f1_m: 0.00%\n",
      "\n",
      "\n",
      "accuracy: 65.69%\n",
      "recall_m: 0.00%\n",
      "precision_m: 0.00%\n",
      "f1_m: 0.00%\n",
      "\n",
      "\n",
      "64.82% (+/- 0.68%)\n",
      "0.08% (+/- 0.11%)\n",
      "0.16% (+/- 0.20%)\n",
      "0.10% (+/- 0.13%)\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(X, y):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(1, 1440), return_sequences=True))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', recall_m, precision_m, f1_m])\n",
    "    \n",
    "    model.fit(X[train], y[train], epochs=10, batch_size=128, verbose=0)\n",
    "    scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "    \n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[2], scores[2]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[3], scores[3]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[4], scores[4]))\n",
    "    print(\"\\n\")\n",
    "    accuracy_scores.append(scores[1] * 100)\n",
    "    prec_scores.append(scores[2])\n",
    "    rec_scores.append(scores[3])\n",
    "    f1_scores.append(scores[4])\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(prec_scores), np.std(prec_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(rec_scores), np.std(rec_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(f1_scores), np.std(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "prec_scores = []\n",
    "rec_scores = []\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 68.93%\n",
      "recall_m: 0.26%\n",
      "precision_m: 0.79%\n",
      "f1_m: 0.35%\n",
      "\n",
      "\n",
      "accuracy: 64.08%\n",
      "recall_m: 0.10%\n",
      "precision_m: 0.33%\n",
      "f1_m: 0.15%\n",
      "\n",
      "\n",
      "accuracy: 62.14%\n",
      "recall_m: 0.06%\n",
      "precision_m: 0.21%\n",
      "f1_m: 0.10%\n",
      "\n",
      "\n",
      "accuracy: 65.05%\n",
      "recall_m: 0.05%\n",
      "precision_m: 0.37%\n",
      "f1_m: 0.09%\n",
      "\n",
      "\n",
      "accuracy: 67.96%\n",
      "recall_m: 0.06%\n",
      "precision_m: 0.50%\n",
      "f1_m: 0.10%\n",
      "\n",
      "\n",
      "accuracy: 64.08%\n",
      "recall_m: 0.02%\n",
      "precision_m: 0.12%\n",
      "f1_m: 0.03%\n",
      "\n",
      "\n",
      "accuracy: 66.99%\n",
      "recall_m: 0.07%\n",
      "precision_m: 0.62%\n",
      "f1_m: 0.12%\n",
      "\n",
      "\n",
      "accuracy: 63.11%\n",
      "recall_m: 0.00%\n",
      "precision_m: 0.00%\n",
      "f1_m: 0.00%\n",
      "\n",
      "\n",
      "accuracy: 66.02%\n",
      "recall_m: 0.07%\n",
      "precision_m: 0.58%\n",
      "f1_m: 0.12%\n",
      "\n",
      "\n",
      "accuracy: 66.67%\n",
      "recall_m: 0.15%\n",
      "precision_m: 0.50%\n",
      "f1_m: 0.21%\n",
      "\n",
      "\n",
      "65.50% (+/- 2.07%)\n",
      "0.08% (+/- 0.07%)\n",
      "0.40% (+/- 0.23%)\n",
      "0.13% (+/- 0.09%)\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(X, y):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(128, input_shape=(1, 1440))))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', recall_m, precision_m, f1_m])\n",
    "    \n",
    "    model.fit(X[train], y[train], epochs=10, batch_size=128, verbose=0)\n",
    "    scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "    \n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[2], scores[2]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[3], scores[3]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[4], scores[4]))\n",
    "    print(\"\\n\")\n",
    "    accuracy_scores.append(scores[1] * 100)\n",
    "    prec_scores.append(scores[2])\n",
    "    rec_scores.append(scores[3])\n",
    "    f1_scores.append(scores[4])\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(prec_scores), np.std(prec_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(rec_scores), np.std(rec_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(f1_scores), np.std(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "prec_scores = []\n",
    "rec_scores = []\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 72.82%\n",
      "recall_m: 0.57%\n",
      "precision_m: 0.66%\n",
      "f1_m: 0.60%\n",
      "\n",
      "\n",
      "accuracy: 66.02%\n",
      "recall_m: 0.55%\n",
      "precision_m: 0.62%\n",
      "f1_m: 0.58%\n",
      "\n",
      "\n",
      "accuracy: 61.17%\n",
      "recall_m: 0.20%\n",
      "precision_m: 0.31%\n",
      "f1_m: 0.24%\n",
      "\n",
      "\n",
      "accuracy: 69.90%\n",
      "recall_m: 0.39%\n",
      "precision_m: 0.46%\n",
      "f1_m: 0.42%\n",
      "\n",
      "\n",
      "accuracy: 67.96%\n",
      "recall_m: 0.57%\n",
      "precision_m: 0.57%\n",
      "f1_m: 0.55%\n",
      "\n",
      "\n",
      "accuracy: 66.99%\n",
      "recall_m: 0.56%\n",
      "precision_m: 0.56%\n",
      "f1_m: 0.54%\n",
      "\n",
      "\n",
      "accuracy: 62.14%\n",
      "recall_m: 0.27%\n",
      "precision_m: 0.36%\n",
      "f1_m: 0.30%\n",
      "\n",
      "\n",
      "accuracy: 61.17%\n",
      "recall_m: 0.32%\n",
      "precision_m: 0.36%\n",
      "f1_m: 0.34%\n",
      "\n",
      "\n",
      "accuracy: 67.96%\n",
      "recall_m: 0.44%\n",
      "precision_m: 0.64%\n",
      "f1_m: 0.52%\n",
      "\n",
      "\n",
      "accuracy: 67.65%\n",
      "recall_m: 0.28%\n",
      "precision_m: 0.42%\n",
      "f1_m: 0.33%\n",
      "\n",
      "\n",
      "66.38% (+/- 3.65%)\n",
      "0.42% (+/- 0.14%)\n",
      "0.50% (+/- 0.12%)\n",
      "0.44% (+/- 0.13%)\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(X, y):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(1, 1440), data_format='channels_first'))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', recall_m, precision_m, f1_m])\n",
    "    \n",
    "    model.fit(X[train], y[train], epochs=10, batch_size=128, verbose=0)\n",
    "    scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "    \n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[2], scores[2]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[3], scores[3]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[4], scores[4]))\n",
    "    print(\"\\n\")\n",
    "    accuracy_scores.append(scores[1] * 100)\n",
    "    prec_scores.append(scores[2])\n",
    "    rec_scores.append(scores[3])\n",
    "    f1_scores.append(scores[4])\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(prec_scores), np.std(prec_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(rec_scores), np.std(rec_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(f1_scores), np.std(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "prec_scores = []\n",
    "rec_scores = []\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 65.05%\n",
      "recall_m: 0.32%\n",
      "precision_m: 0.47%\n",
      "f1_m: 0.37%\n",
      "\n",
      "\n",
      "accuracy: 69.90%\n",
      "recall_m: 0.44%\n",
      "precision_m: 0.41%\n",
      "f1_m: 0.42%\n",
      "\n",
      "\n",
      "accuracy: 69.90%\n",
      "recall_m: 0.20%\n",
      "precision_m: 0.55%\n",
      "f1_m: 0.29%\n",
      "\n",
      "\n",
      "accuracy: 62.14%\n",
      "recall_m: 0.14%\n",
      "precision_m: 0.40%\n",
      "f1_m: 0.20%\n",
      "\n",
      "\n",
      "accuracy: 69.90%\n",
      "recall_m: 0.73%\n",
      "precision_m: 0.59%\n",
      "f1_m: 0.64%\n",
      "\n",
      "\n",
      "accuracy: 60.19%\n",
      "recall_m: 0.68%\n",
      "precision_m: 0.46%\n",
      "f1_m: 0.54%\n",
      "\n",
      "\n",
      "accuracy: 70.87%\n",
      "recall_m: 0.70%\n",
      "precision_m: 0.57%\n",
      "f1_m: 0.61%\n",
      "\n",
      "\n",
      "accuracy: 63.11%\n",
      "recall_m: 0.08%\n",
      "precision_m: 0.46%\n",
      "f1_m: 0.13%\n",
      "\n",
      "\n",
      "accuracy: 63.11%\n",
      "recall_m: 0.55%\n",
      "precision_m: 0.51%\n",
      "f1_m: 0.53%\n",
      "\n",
      "\n",
      "accuracy: 68.63%\n",
      "recall_m: 0.18%\n",
      "precision_m: 0.50%\n",
      "f1_m: 0.27%\n",
      "\n",
      "\n",
      "66.28% (+/- 3.77%)\n",
      "0.40% (+/- 0.24%)\n",
      "0.49% (+/- 0.06%)\n",
      "0.40% (+/- 0.17%)\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(X, y):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(1, 1440), data_format='channels_first'))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', recall_m, precision_m, f1_m])\n",
    "    \n",
    "    model.fit(X[train], y[train], epochs=10, batch_size=128, verbose=0)\n",
    "    scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "    \n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[2], scores[2]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[3], scores[3]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[4], scores[4]))\n",
    "    print(\"\\n\")\n",
    "    accuracy_scores.append(scores[1] * 100)\n",
    "    prec_scores.append(scores[2])\n",
    "    rec_scores.append(scores[3])\n",
    "    f1_scores.append(scores[4])\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(prec_scores), np.std(prec_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(rec_scores), np.std(rec_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(f1_scores), np.std(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
