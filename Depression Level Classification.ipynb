{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>days</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>afftype</th>\n",
       "      <th>melanch</th>\n",
       "      <th>inpatient</th>\n",
       "      <th>edu</th>\n",
       "      <th>marriage</th>\n",
       "      <th>work</th>\n",
       "      <th>madrs1</th>\n",
       "      <th>madrs2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>condition_1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>35-39</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>condition_2</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>40-44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>condition_3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>45-49</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>condition_4</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>25-29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>condition_5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>50-54</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11-15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        number  days  gender    age  afftype  melanch  inpatient    edu  \\\n",
       "0  condition_1    11       2  35-39      2.0      2.0        2.0   6-10   \n",
       "1  condition_2    18       2  40-44      1.0      2.0        2.0   6-10   \n",
       "2  condition_3    13       1  45-49      2.0      2.0        2.0   6-10   \n",
       "3  condition_4    13       2  25-29      2.0      2.0        2.0  11-15   \n",
       "4  condition_5    13       2  50-54      2.0      2.0        2.0  11-15   \n",
       "\n",
       "   marriage  work  madrs1  madrs2  \n",
       "0       1.0   2.0    19.0    19.0  \n",
       "1       2.0   2.0    24.0    11.0  \n",
       "2       2.0   2.0    24.0    25.0  \n",
       "3       1.0   1.0    20.0    16.0  \n",
       "4       2.0   2.0    26.0    26.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DepressionLevelsFile = \"data/scores.csv\"\n",
    "dperessionLevelsData = pd.read_csv(DepressionLevelsFile)\n",
    "dperessionLevelsData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = dperessionLevelsData['number'][:23]\n",
    "MADRS1 = dperessionLevelsData['madrs1'][:23]\n",
    "MADRS2 = dperessionLevelsData['madrs2'][:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MADRS_scores = []\n",
    "for x in range(len(MADRS1)):\n",
    "    avg_score = (int(MADRS1[x]) + int(MADRS2[x])) / 2\n",
    "    if avg_score >= 7 and avg_score <= 19:\n",
    "        MADRS_scores.append(0)\n",
    "    if avg_score >= 20 and avg_score <= 34:\n",
    "        MADRS_scores.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NameDepLevelMap = dict(zip(names, MADRS_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'condition_1': 0,\n",
       " 'condition_2': 0,\n",
       " 'condition_3': 1,\n",
       " 'condition_4': 0,\n",
       " 'condition_5': 1,\n",
       " 'condition_6': 0,\n",
       " 'condition_7': 1,\n",
       " 'condition_8': 0,\n",
       " 'condition_9': 1,\n",
       " 'condition_10': 1,\n",
       " 'condition_11': 1,\n",
       " 'condition_12': 1,\n",
       " 'condition_13': 0,\n",
       " 'condition_14': 1,\n",
       " 'condition_15': 0,\n",
       " 'condition_16': 0,\n",
       " 'condition_17': 0,\n",
       " 'condition_18': 0,\n",
       " 'condition_19': 1,\n",
       " 'condition_20': 1,\n",
       " 'condition_21': 1,\n",
       " 'condition_22': 1,\n",
       " 'condition_23': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NameDepLevelMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConditionGroupFileNames = os.listdir('data/condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileName in ConditionGroupFileNames:\n",
    "    df = pd.read_csv('data/condition/'+str(fileName))\n",
    "    dates = df['date'].unique()\n",
    "    activityLevelsPerDay = []\n",
    "    for date in dates:\n",
    "        if len(df[df['date']==date]) == 1440:\n",
    "            temp = pd.DataFrame(df[df['date']==date]).drop(columns=['timestamp','date'])\n",
    "            activityLevelsPerDay.append(temp)\n",
    "    for dailyActivityLevel in activityLevelsPerDay:\n",
    "        activityVector = np.array(dailyActivityLevel[\"activity\"])\n",
    "        if len(activityVector) == 1440:\n",
    "            X.append(activityVector)\n",
    "            y.append(NameDepLevelMap[str(fileName[:-4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDict = list(zip(X, y))\n",
    "random.shuffle(combinedDict)\n",
    "X[:], y[:] = zip(*combinedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(X, (X.shape[0], 1, X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "accuracy_scores = []\n",
    "prec_scores = []\n",
    "rec_scores = []\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 56.76%\n",
      "recall_m: 0.69%\n",
      "precision_m: 0.46%\n",
      "f1_m: 0.56%\n",
      "\n",
      "\n",
      "accuracy: 63.89%\n",
      "recall_m: 0.50%\n",
      "precision_m: 0.34%\n",
      "f1_m: 0.40%\n",
      "\n",
      "\n",
      "accuracy: 55.56%\n",
      "recall_m: 0.58%\n",
      "precision_m: 0.76%\n",
      "f1_m: 0.63%\n",
      "\n",
      "\n",
      "accuracy: 66.67%\n",
      "recall_m: 1.00%\n",
      "precision_m: 0.64%\n",
      "f1_m: 0.78%\n",
      "\n",
      "\n",
      "accuracy: 58.33%\n",
      "recall_m: 0.84%\n",
      "precision_m: 0.76%\n",
      "f1_m: 0.76%\n",
      "\n",
      "\n",
      "accuracy: 55.56%\n",
      "recall_m: 0.94%\n",
      "precision_m: 0.53%\n",
      "f1_m: 0.67%\n",
      "\n",
      "\n",
      "accuracy: 69.44%\n",
      "recall_m: 0.97%\n",
      "precision_m: 0.80%\n",
      "f1_m: 0.87%\n",
      "\n",
      "\n",
      "accuracy: 58.33%\n",
      "recall_m: 0.94%\n",
      "precision_m: 0.54%\n",
      "f1_m: 0.68%\n",
      "\n",
      "\n",
      "accuracy: 62.86%\n",
      "recall_m: 0.69%\n",
      "precision_m: 0.56%\n",
      "f1_m: 0.62%\n",
      "\n",
      "\n",
      "accuracy: 60.00%\n",
      "recall_m: 0.91%\n",
      "precision_m: 0.62%\n",
      "f1_m: 0.74%\n",
      "\n",
      "\n",
      "60.74% (+/- 4.55%)\n",
      "0.81% (+/- 0.17%)\n",
      "0.60% (+/- 0.14%)\n",
      "0.67% (+/- 0.12%)\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(X, y):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(1, 1440), return_sequences=True))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', recall_m, precision_m, f1_m])\n",
    "    \n",
    "    model.fit(X[train], y[train], epochs=10, batch_size=128, verbose=0)\n",
    "    scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "    \n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[2], scores[2]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[3], scores[3]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[4], scores[4]))\n",
    "    print(\"\\n\")\n",
    "    accuracy_scores.append(scores[1] * 100)\n",
    "    prec_scores.append(scores[2])\n",
    "    rec_scores.append(scores[3])\n",
    "    f1_scores.append(scores[4])\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(prec_scores), np.std(prec_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(rec_scores), np.std(rec_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(f1_scores), np.std(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "prec_scores = []\n",
    "rec_scores = []\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 59.46%\n",
      "recall_m: 0.83%\n",
      "precision_m: 0.63%\n",
      "f1_m: 0.72%\n",
      "\n",
      "\n",
      "accuracy: 52.78%\n",
      "recall_m: 0.92%\n",
      "precision_m: 0.44%\n",
      "f1_m: 0.58%\n",
      "\n",
      "\n",
      "accuracy: 44.44%\n",
      "recall_m: 0.42%\n",
      "precision_m: 0.49%\n",
      "f1_m: 0.44%\n",
      "\n",
      "\n",
      "accuracy: 41.67%\n",
      "recall_m: 0.33%\n",
      "precision_m: 0.26%\n",
      "f1_m: 0.29%\n",
      "\n",
      "\n",
      "accuracy: 66.67%\n",
      "recall_m: 0.88%\n",
      "precision_m: 0.80%\n",
      "f1_m: 0.83%\n",
      "\n",
      "\n",
      "accuracy: 69.44%\n",
      "recall_m: 0.91%\n",
      "precision_m: 0.67%\n",
      "f1_m: 0.77%\n",
      "\n",
      "\n",
      "accuracy: 66.67%\n",
      "recall_m: 0.74%\n",
      "precision_m: 0.81%\n",
      "f1_m: 0.75%\n",
      "\n",
      "\n",
      "accuracy: 55.56%\n",
      "recall_m: 0.68%\n",
      "precision_m: 0.61%\n",
      "f1_m: 0.64%\n",
      "\n",
      "\n",
      "accuracy: 74.29%\n",
      "recall_m: 0.72%\n",
      "precision_m: 0.61%\n",
      "f1_m: 0.66%\n",
      "\n",
      "\n",
      "accuracy: 54.29%\n",
      "recall_m: 0.88%\n",
      "precision_m: 0.76%\n",
      "f1_m: 0.81%\n",
      "\n",
      "\n",
      "58.53% (+/- 10.21%)\n",
      "0.73% (+/- 0.20%)\n",
      "0.61% (+/- 0.16%)\n",
      "0.65% (+/- 0.16%)\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(X, y):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(128, input_shape=(1, 1440))))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', recall_m, precision_m, f1_m])\n",
    "    \n",
    "    model.fit(X[train], y[train], epochs=10, batch_size=128, verbose=0)\n",
    "    scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "    \n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[2], scores[2]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[3], scores[3]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[4], scores[4]))\n",
    "    print(\"\\n\")\n",
    "    accuracy_scores.append(scores[1] * 100)\n",
    "    prec_scores.append(scores[2])\n",
    "    rec_scores.append(scores[3])\n",
    "    f1_scores.append(scores[4])\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(prec_scores), np.std(prec_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(rec_scores), np.std(rec_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(f1_scores), np.std(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "prec_scores = []\n",
    "rec_scores = []\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 59.46%\n",
      "recall_m: 0.69%\n",
      "precision_m: 0.68%\n",
      "f1_m: 0.65%\n",
      "\n",
      "\n",
      "accuracy: 47.22%\n",
      "recall_m: 0.83%\n",
      "precision_m: 0.43%\n",
      "f1_m: 0.54%\n",
      "\n",
      "\n",
      "accuracy: 36.11%\n",
      "recall_m: 0.46%\n",
      "precision_m: 0.64%\n",
      "f1_m: 0.53%\n",
      "\n",
      "\n",
      "accuracy: 55.56%\n",
      "recall_m: 0.31%\n",
      "precision_m: 0.32%\n",
      "f1_m: 0.31%\n",
      "\n",
      "\n",
      "accuracy: 61.11%\n",
      "recall_m: 0.71%\n",
      "precision_m: 0.79%\n",
      "f1_m: 0.72%\n",
      "\n",
      "\n",
      "accuracy: 61.11%\n",
      "recall_m: 0.60%\n",
      "precision_m: 0.50%\n",
      "f1_m: 0.54%\n",
      "\n",
      "\n",
      "accuracy: 47.22%\n",
      "recall_m: 0.61%\n",
      "precision_m: 0.57%\n",
      "f1_m: 0.59%\n",
      "\n",
      "\n",
      "accuracy: 55.56%\n",
      "recall_m: 0.55%\n",
      "precision_m: 0.62%\n",
      "f1_m: 0.58%\n",
      "\n",
      "\n",
      "accuracy: 60.00%\n",
      "recall_m: 0.43%\n",
      "precision_m: 0.68%\n",
      "f1_m: 0.50%\n",
      "\n",
      "\n",
      "accuracy: 51.43%\n",
      "recall_m: 0.74%\n",
      "precision_m: 0.60%\n",
      "f1_m: 0.65%\n",
      "\n",
      "\n",
      "53.48% (+/- 7.67%)\n",
      "0.59% (+/- 0.15%)\n",
      "0.58% (+/- 0.13%)\n",
      "0.56% (+/- 0.10%)\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(X, y):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(1, 1440), data_format='channels_first'))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', recall_m, precision_m, f1_m])\n",
    "    \n",
    "    model.fit(X[train], y[train], epochs=10, batch_size=128, verbose=0)\n",
    "    scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "    \n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[2], scores[2]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[3], scores[3]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[4], scores[4]))\n",
    "    print(\"\\n\")\n",
    "    accuracy_scores.append(scores[1] * 100)\n",
    "    prec_scores.append(scores[2])\n",
    "    rec_scores.append(scores[3])\n",
    "    f1_scores.append(scores[4])\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(prec_scores), np.std(prec_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(rec_scores), np.std(rec_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(f1_scores), np.std(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "prec_scores = []\n",
    "rec_scores = []\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 48.65%\n",
      "recall_m: 0.81%\n",
      "precision_m: 0.74%\n",
      "f1_m: 0.77%\n",
      "\n",
      "\n",
      "accuracy: 52.78%\n",
      "recall_m: 0.86%\n",
      "precision_m: 0.52%\n",
      "f1_m: 0.64%\n",
      "\n",
      "\n",
      "accuracy: 63.89%\n",
      "recall_m: 0.73%\n",
      "precision_m: 0.79%\n",
      "f1_m: 0.76%\n",
      "\n",
      "\n",
      "accuracy: 61.11%\n",
      "recall_m: 0.33%\n",
      "precision_m: 0.33%\n",
      "f1_m: 0.33%\n",
      "\n",
      "\n",
      "accuracy: 77.78%\n",
      "recall_m: 0.68%\n",
      "precision_m: 0.88%\n",
      "f1_m: 0.74%\n",
      "\n",
      "\n",
      "accuracy: 72.22%\n",
      "recall_m: 0.82%\n",
      "precision_m: 0.73%\n",
      "f1_m: 0.75%\n",
      "\n",
      "\n",
      "accuracy: 58.33%\n",
      "recall_m: 0.52%\n",
      "precision_m: 0.80%\n",
      "f1_m: 0.63%\n",
      "\n",
      "\n",
      "accuracy: 61.11%\n",
      "recall_m: 0.61%\n",
      "precision_m: 0.65%\n",
      "f1_m: 0.63%\n",
      "\n",
      "\n",
      "accuracy: 51.43%\n",
      "recall_m: 0.74%\n",
      "precision_m: 0.60%\n",
      "f1_m: 0.65%\n",
      "\n",
      "\n",
      "accuracy: 65.71%\n",
      "recall_m: 0.88%\n",
      "precision_m: 0.66%\n",
      "f1_m: 0.75%\n",
      "\n",
      "\n",
      "61.30% (+/- 8.69%)\n",
      "0.70% (+/- 0.16%)\n",
      "0.67% (+/- 0.15%)\n",
      "0.67% (+/- 0.12%)\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(X, y):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(1, 1440), data_format='channels_first'))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', recall_m, precision_m, f1_m])\n",
    "    \n",
    "    model.fit(X[train], y[train], epochs=10, batch_size=128, verbose=0)\n",
    "    scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "    \n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[2], scores[2]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[3], scores[3]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[4], scores[4]))\n",
    "    print(\"\\n\")\n",
    "    accuracy_scores.append(scores[1] * 100)\n",
    "    prec_scores.append(scores[2])\n",
    "    rec_scores.append(scores[3])\n",
    "    f1_scores.append(scores[4])\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(prec_scores), np.std(prec_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(rec_scores), np.std(rec_scores)))\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(f1_scores), np.std(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
